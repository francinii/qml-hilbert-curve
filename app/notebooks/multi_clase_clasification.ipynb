{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ba1c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Tuple, List\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, recall_score, f1_score\n",
    "from sklearn.datasets import fetch_openml\n",
    "import pennylane as qml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4347a21",
   "metadata": {},
   "source": [
    "### Constants \n",
    "This section defines important constants and configuration variables used throughout the notebook.\n",
    " \n",
    "- `CLASS_MAP`: A dictionary mapping each tumor class name to a unique integer label. This is used for encoding categorical labels into numerical form for model training and evaluation.\n",
    "- `CLASS_MAP_NUMBER`: The total number of classes in the classification problem, derived from the length of `CLASS_MAP`.\n",
    "- `BASE_URL`, `TRAINING_URL`, `TESTING_URL`: Paths to the dataset directories. These are used to load training and testing data.\n",
    "- `RESULTS_GRAPHICS_URL`, `RESULTS_CSV_URL`: Paths where the results (such as plots and CSV files) will be saved.\n",
    " \n",
    "You can modify these constants to adapt the notebook to different datasets or directory structures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ffc0cb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_MAP = {\n",
    "        \"glioma_tumor\": 0,        \n",
    "        \"pituitary_tumor\": 1,\n",
    "        \"no_tumor\": 2\n",
    "    }\n",
    "CLASS_MAP_NUMBER = len(CLASS_MAP)\n",
    "BASE_URL= \"../data/dataset_multiclase/\"\n",
    "TRAINING_URL= BASE_URL + \"Training/\"\n",
    "TESTING_URL= BASE_URL + \"Testing/\"\n",
    "RESULTS_GRAPHICS_URL = '../results/graphics/'\n",
    "RESULTS_CSV_URL = '../results/csv/'\n",
    "RESULTS_MODELS_URL = '../results/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "370b2c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotUtils:\n",
    "    @staticmethod\n",
    "    def plot_loss(loss_history, title='Loss function by epochs', save_path=None):\n",
    "        plt.figure()\n",
    "        plt.plot(loss_history, marker='o')\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid(True)\n",
    "        if save_path:\n",
    "            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_confusion_matrix(cm, class_names=None, title='Confusion Matrix', save_path=None):\n",
    "        plt.figure()\n",
    "        xticks = class_names if class_names is not None else 'auto'\n",
    "        yticks = class_names if class_names is not None else 'auto'\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=xticks, yticklabels=yticks)\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Prediction')\n",
    "        plt.ylabel('Real')\n",
    "        if save_path:\n",
    "            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47049d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_multiclass(\n",
    "    data_dir: str = TRAINING_URL,\n",
    "    image_size: int = 128, ## Revisar el tamano de la imagen\n",
    "    seed: int = 42\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Carga, redimensiona y etiqueta imágenes de las 4 clases para clasificación multiclase.\n",
    "    Devuelve (X, y) como arrays de numpy.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    class_map = CLASS_MAP\n",
    "    files_by_class = {}\n",
    "    for class_name in class_map:\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        files = [os.path.join(class_dir, f) for f in os.listdir(class_dir) if f.lower().endswith('.jpg')]\n",
    "        files_by_class[class_name] = files\n",
    "    X, y = [], []\n",
    "    for class_name, label in class_map.items():\n",
    "        for f in files_by_class[class_name]:\n",
    "            img = Image.open(f).convert('L').resize((image_size, image_size)) ### revisar si esto tiene interpolacion! \n",
    "            X.append(np.array(img))\n",
    "            y.append(label)\n",
    "    X = np.stack(X)\n",
    "    y = np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumClassifier:\n",
    "    def __init__(self, n_qubits=8, pca_features=8, batch_size=16, epochs=20, lr=0.01, layers=3, seed=42):\n",
    "        self.n_qubits = n_qubits\n",
    "        self.pca_features = pca_features\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.layers = layers\n",
    "        self.seed = seed\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        self._prepare_data_custom()\n",
    "        self._build_model()\n",
    "\n",
    "    def prepare_data(self, data_dir):\n",
    "        X, y = prepare_data_multiclass(data_dir=data_dir, image_size=256, seed=self.seed)\n",
    "        X = X.reshape((X.shape[0], -1)) / 255.0  # flatten and normalize\n",
    "        scaler = StandardScaler() ### verificar este metodo \n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        pca = PCA(n_components=self.pca_features) ######## TODO  probar otros puede ser autoencoding\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        scaler_angle = MinMaxScaler(feature_range=(0, np.pi / 2))\n",
    "        x_train = scaler_angle.fit_transform(X_pca)\n",
    "        return x_train, y        \n",
    "\n",
    "    def _prepare_data_custom(self):\n",
    "        x_train, y_train =self.prepare_data(TRAINING_URL)\n",
    "        x_test, y_test =self.prepare_data(TESTING_URL)\n",
    "        self.x_train = x_train\n",
    "        self.x_test = x_test\n",
    "        self.y_train = np.array(y_train)\n",
    "        self.y_test = np.array(y_test)\n",
    "\n",
    "    def _build_model(self):\n",
    "        dev = qml.device(\"lightning.qubit\", wires=self.n_qubits)\n",
    "        def circuit(inputs, weights): #hacer varias capas cuanticas \n",
    "            qml.AngleEmbedding(inputs, wires=range(self.n_qubits), rotation='Y')\n",
    "            # Encoding aca con cnot verificar si estose esta aplicando \n",
    "            # StronglyEntanglerLayers justificar porque se usa uno u otro\n",
    "            #\n",
    "            qml.templates.BasicEntanglerLayers(weights, wires=range(self.n_qubits))\n",
    "            return [qml.expval(qml.PauliZ(i)) for i in range(self.n_qubits)]\n",
    "        weight_shapes = {\"weights\": (self.layers, self.n_qubits)}\n",
    "        qlayer = qml.qnn.TorchLayer(qml.qnode(dev)(circuit), weight_shapes)\n",
    "\n",
    "        class HybridModel(nn.Module):\n",
    "            ### Datos para entrenar\n",
    "            ### Circuito rotaciones \n",
    "            ### Circuito \n",
    "            ###  Cnots que hcaen entanglement\n",
    "            ### exval qnn evitar mezclarlos \n",
    "            #variational entablement en sandwwich \n",
    "            def __init__(self, qlayer, n_classes=CLASS_MAP_NUMBER, n_qubits_model=None, input_features=None):\n",
    "                super().__init__()\n",
    "                self.fc_input = nn.Linear(input_features, n_qubits_model)\n",
    "                self.qlayer = qlayer # Aca agregamos una capa de QML  ### \n",
    "                # TODO revisar el QML de pennylane\n",
    "                self.bn1 = nn.BatchNorm1d(n_qubits_model)\n",
    "                self.hidden1 = nn.Linear(n_qubits_model, 64)\n",
    "                self.dropout1 = nn.Dropout(0.3) ##### \n",
    "                self.hidden2 = nn.Linear(64, 32)\n",
    "                self.dropout2 = nn.Dropout(0.2)\n",
    "                self.hidden3 = nn.Linear(32, 16)\n",
    "                self.dropout3 = nn.Dropout(0.3)\n",
    "                self.hidden4 = nn.Linear(16, 8)\n",
    "                self.dropout4 = nn.Dropout(0.3)\n",
    "                self.output = nn.Linear(8, n_classes)                \n",
    "                self.relu = nn.ReLU()\n",
    "            def forward(self, x):\n",
    "                x = self.fc_input(x)\n",
    "                x = self.qlayer(x)\n",
    "                x = self.bn1(x)\n",
    "                x = self.relu(self.hidden1(x))\n",
    "                x = self.dropout1(x)\n",
    "                x = self.relu(self.hidden2(x))\n",
    "                x = self.dropout2(x)\n",
    "                x = self.relu(self.hidden3(x))\n",
    "                x = self.dropout3(x)\n",
    "                x = self.relu(self.hidden4(x))\n",
    "                x = self.dropout4(x)\n",
    "                return self.output(x)\n",
    "        self.model = HybridModel(qlayer, n_classes=CLASS_MAP_NUMBER, n_qubits_model=self.n_qubits, input_features=self.pca_features)\n",
    "\n",
    "    def train_and_evaluate(self):\n",
    "        x_train_t = torch.tensor(self.x_train, dtype=torch.float32)\n",
    "        y_train_t = torch.tensor(self.y_train, dtype=torch.long)\n",
    "        train_loader = DataLoader(TensorDataset(x_train_t, y_train_t), batch_size=self.batch_size, shuffle=True)\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=10, factor=0.8)\n",
    "        loss_history = []\n",
    "        start = time.time()\n",
    "        epoch_results = []\n",
    "        print(f\"---------------EPOCHS--------------------\")\n",
    "        for epoch in range(self.epochs):\n",
    "            self.model.train() # Set model to training mode\n",
    "            for xb, yb in train_loader:\n",
    "                pred = self.model(xb)\n",
    "                loss = loss_fn(pred, yb)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            loss_history.append(loss.item())\n",
    "\n",
    "            # Evaluate on test set at the end of each epoch to get accuracy\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                x_test_t_epoch = torch.tensor(self.x_test, dtype=torch.float32)\n",
    "                y_test_t_epoch = torch.tensor(self.y_test, dtype=torch.long)\n",
    "                preds_epoch = self.model(x_test_t_epoch)\n",
    "                preds_cls_epoch = torch.argmax(preds_epoch, dim=1)\n",
    "                current_acc = (preds_cls_epoch == y_test_t_epoch).float().mean().item()\n",
    "\n",
    "            print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}, Accuracy = {current_acc:.4f}\")\n",
    "            scheduler.step(loss.item())\n",
    "            for param_group in optimizer.param_groups:\n",
    "                print(\"Current LR:\", param_group['lr'])\n",
    "\n",
    "            # Store epoch results for later sorting\n",
    "            epoch_results.append((current_acc, epoch + 1, self.model.state_dict()))\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        # Sort results by accuracy in descending order and get the top 2\n",
    "        epoch_results.sort(key=lambda x: x[0], reverse=True)\n",
    "        top_two_epochs = epoch_results[:2]\n",
    "\n",
    "        print(\"\\nSaving top 2 models:\")\n",
    "        for acc, ep, state_dict in top_two_epochs:\n",
    "            self._save_model(state_dict, ep, acc, RESULTS_MODELS_URL)\n",
    "\n",
    "        # --- The rest of your existing evaluation and logging code ---\n",
    "        # This part will evaluate the model *after* all epochs are done,\n",
    "        # which means it reflects the performance of the *last* epoch.\n",
    "        # The 'acc' variable here will be the accuracy of the last epoch,\n",
    "        # not necessarily one of the top two saved.\n",
    "        with torch.no_grad():\n",
    "            x_test_t = torch.tensor(self.x_test, dtype=torch.float32)\n",
    "            y_test_t = torch.tensor(self.y_test, dtype=torch.long)\n",
    "            preds = self.model(x_test_t)\n",
    "            preds_cls = torch.argmax(preds, dim=1)\n",
    "            acc = (preds_cls == y_test_t).float().mean().item() # This 'acc' is for the last epoch\n",
    "            cm = confusion_matrix(y_test_t.cpu().numpy(), preds_cls.cpu().numpy())\n",
    "            recall = recall_score(y_test_t.cpu().numpy(), preds_cls.cpu().numpy(), average='macro')\n",
    "            f1 = f1_score(y_test_t.cpu().numpy(), preds_cls.cpu().numpy(), average='macro')\n",
    "\n",
    "        sorted_items = sorted(CLASS_MAP.items(), key=lambda item: item[1])\n",
    "        class_names = [name for name, _ in sorted_items]\n",
    "\n",
    "        PlotUtils.plot_loss(loss_history, save_path=RESULTS_GRAPHICS_URL + 'MC_loss_function_pen.png')\n",
    "        PlotUtils.plot_confusion_matrix(cm, class_names=class_names, save_path=RESULTS_GRAPHICS_URL +'MC_confusion_matrix_pen.png')\n",
    "\n",
    "        results = {\n",
    "            'epochs': self.epochs,\n",
    "            'learning_rate': self.lr,\n",
    "            'features': self.pca_features,\n",
    "            'layers': self.layers,\n",
    "            'batch_size': self.batch_size,\n",
    "            'loss': float(loss.item()), # Last epoch's loss\n",
    "            'accuracy': acc, # Last epoch's accuracy\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'confusion_matrix': cm.tolist(),\n",
    "            'execution_time': end - start\n",
    "        }\n",
    "        print(f\"Accuracy (last epoch): {acc:.4f}\")\n",
    "        print(\"Confusion Matrix:\\\\n\", cm)\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 score: {f1:.4f}\")\n",
    "        return results\n",
    "\n",
    "    def _save_model(self, model_state_dict, epoch, accuracy, save_dir):\n",
    "        \"\"\"\n",
    "        Saves the model state dictionary to a specified directory\n",
    "        with a structured filename.\n",
    "        \"\"\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        filename = f\"MC_best_model_epoch_{epoch}_acc_{accuracy:.4f}.pt\"\n",
    "        filepath = os.path.join(save_dir, filename)\n",
    "        torch.save(model_state_dict, filepath)\n",
    "        print(f\"Model saved: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dd15946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentRunner:\n",
    "    def __init__(self, epochs, lr, features, layers, batch_size, seed):\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.features = features\n",
    "        self.layers = layers\n",
    "        self.batch_size = batch_size\n",
    "        self.seed = seed\n",
    "\n",
    "    def csv_log(self, results, csv_file):\n",
    "        \"\"\"\n",
    "        Logs experiment results to a CSV file.\n",
    "\n",
    "        Args:\n",
    "            results (dict): Dictionary containing experiment results, including 'execution_time'.\n",
    "            csv_file (str): Path to the CSV file where results will be saved.\n",
    "        \"\"\"\n",
    "        duration_seconds = results.get('execution_time', None)\n",
    "        log_date = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        header = [\n",
    "            'date', 'execution_time_seconds', 'epochs', 'learning_rate', 'features', 'layers', 'batch_size',\n",
    "            'loss', 'accuracy', 'recall', 'f1_score'\n",
    "        ]\n",
    "        row = [\n",
    "            log_date, f'{duration_seconds:.2f}' if duration_seconds is not None else '',\n",
    "            results.get('epochs'), results.get('learning_rate'), results.get('features'),\n",
    "            results.get('layers'), results.get('batch_size'), results.get('loss'),\n",
    "            results.get('accuracy'), results.get('recall'), results.get('f1_score')\n",
    "        ]\n",
    "        file_exists = os.path.isfile(csv_file)\n",
    "        with open(csv_file, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            if not file_exists:\n",
    "                writer.writerow(header)\n",
    "            writer.writerow(row)\n",
    "        print(f'Results saved to {csv_file}')\n",
    "        print('Run summary:')\n",
    "        print(row)\n",
    "\n",
    "\n",
    "    def log_class_distribution(self,unique_classes, counts, data_type):\n",
    "        \"\"\"\n",
    "        Logs the distribution of classes in a dataset.\n",
    "\n",
    "        Args:\n",
    "            unique_classes (np.ndarray): Array of unique class labels.\n",
    "            counts (np.ndarray): Array of counts for each unique class.\n",
    "            data_type (str): A string describing the type of data (e.g., \"training data\", \"test data\").\n",
    "        \"\"\"\n",
    "        print(f\"Distribution of classes in {data_type}:\")\n",
    "        for cls, count in zip(unique_classes, counts):\n",
    "            print(f\"  Class {cls}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0912bdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumRunner(ExperimentRunner):\n",
    "    def run(self):\n",
    "        print(\"\\n--- Running QU⌈ANTUM QuantumClassifier ---\")\n",
    "        qc = QuantumClassifier(\n",
    "            n_qubits=self.features,\n",
    "            pca_features=self.features,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            lr=self.lr,\n",
    "            layers=self.layers,\n",
    "            seed=self.seed\n",
    "        )\n",
    "        unique_classes_train, counts_train = np.unique(qc.y_train, return_counts=True)\n",
    "        self.log_class_distribution(unique_classes_train, counts_train, \"training data (y_train)\")\n",
    "\n",
    "        unique_classes_test, counts_test = np.unique(qc.y_test, return_counts=True)\n",
    "        self.log_class_distribution(unique_classes_test, counts_test, \"test data (y_test)\")\n",
    "        # ... existing code ...\n",
    "        start_time = time.time()\n",
    "        results = qc.train_and_evaluate()\n",
    "        end_time = time.time()\n",
    "        self.duration = end_time - start_time\n",
    "        results['execution_time'] = self.duration\n",
    "        self.csv_log(results, RESULTS_CSV_URL+'MC_results_log_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "927f10c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "#### CONFIGURATION CONSTANTS\n",
    "# =====================\n",
    "MODE = 'quantum'  # Options: 'quantum', 'quantum_hilbert', 'both'\n",
    "EPOCHS = 4\n",
    "# CONFIGURACIÓN SUGERIDA\n",
    "LEARNING_RATE = 0.001 # O incluso 0.001\n",
    "FEATURES = 8 #numero de qubits width del circuito cuantico\n",
    "LAYERS = 10 # profundidad del circuito cuantico\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42\n",
    "USE_HILBERT = True  # Only relevant for quantum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8fee7a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running QU⌈ANTUM QuantumClassifier ---\n",
      "Distribution of classes in training data (y_train):\n",
      "  Class 0: 2000 samples\n",
      "  Class 1: 2000 samples\n",
      "  Class 2: 2000 samples\n",
      "Distribution of classes in test data (y_test):\n",
      "  Class 0: 250 samples\n",
      "  Class 1: 250 samples\n",
      "  Class 2: 250 samples\n",
      "---------------EPOCHS--------------------\n",
      "Epoch 1: Loss = 0.8373, Accuracy = 0.5640\n",
      "Current LR: 0.001\n",
      "Epoch 2: Loss = 1.0845, Accuracy = 0.6240\n",
      "Current LR: 0.001\n",
      "Epoch 3: Loss = 0.7252, Accuracy = 0.6960\n",
      "Current LR: 0.001\n",
      "Epoch 4: Loss = 0.7710, Accuracy = 0.7320\n",
      "Current LR: 0.001\n",
      "\n",
      "Saving top 2 models:\n",
      "Model saved: ../results/models\\MC_best_model_epoch_4_acc_0.7320.pt\n",
      "Model saved: ../results/models\\MC_best_model_epoch_3_acc_0.6960.pt\n",
      "Accuracy (last epoch): 0.7320\n",
      "Confusion Matrix:\\n [[225  20   5]\n",
      " [ 49 184  17]\n",
      " [ 57  53 140]]\n",
      "Recall: 0.7320\n",
      "F1 score: 0.7267\n",
      "Results saved to ../results/csv/MC_results_log_.csv\n",
      "Run summary:\n",
      "['2025-07-15 23:08:52', '199.29', 4, 0.001, 8, 10, 32, 0.7710404396057129, 0.7319999933242798, 0.7320000000000001, 0.726658864308792]\n"
     ]
    }
   ],
   "source": [
    "QuantumRunner(EPOCHS, LEARNING_RATE, FEATURES, LAYERS, BATCH_SIZE, SEED).run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
